## 答辩意见
某某某同学（针对...问题开展研究工作）（系统开展了...等方面的研究），选题具有重要的（理论意义）（和实用价值）。（分析了...），（开发了...），（实现了...），（探讨了...），（...），（圆满、很好地）完成了毕业设计任务书规定的任务，工作量饱满。
该生工作作风严谨务实，论文格式标准，（层次清晰），（文理通顺），（图表规范），（结构严谨），（逻辑性强）。答辩中叙述流畅，能够在规定时间内（熟练）、（扼要）地陈述论文的主要内容，（条理清晰），回答问题清楚，（思路清晰），表达准确。
经答辩委员会评议，同意该生通过毕业答辩，并评定成绩为优秀，建议授予学士学位。

潘志清同学系统开展了上海市共享单车骑行轨迹通勤模式方面的研究，选题具有理论意义和实用价值。开发了针对骑行轨迹数据的预处理及时空分析框架，探讨了骑行时空通勤模式及共享单车供求潮汐模式等问题，很好地完成了毕业设计任务书规定的任务，工作量饱满。该生工作作风严谨务实，论文格式标准，层次清晰，图表规范。答辩中叙述流畅，能够在规定时间内熟练地陈述论文的主要内容，回答问题清楚，表达准确。经答辩委员会评议，同意该生通过毕业答辩，并评定成绩为优秀，建议授予学士学位。

## 答辩记录
1. 轨迹数据源是什么？文本文件格式的还是什么别的格式？
   - 轨迹数据是在互联网上采集的，主要是哈啰单车公司的真实业务数据。原始数据是CSV格式的，也就是一种以逗号为分割符的表格文件。在这个文件中，轨迹数据是单独一列存储，与订单编号、时间戳这些是并排的。单个轨迹是一个以井号分割的字符串，所以需要做一些预先处理才能比较易用。

2. 我看你这个研究用到的数据量很大，你是怎么管理这些数据的？有没有遇到什么难点或者说耗费时间的地方？
   - 确实，数据量比较大。我主要采用“分而治之”的处理思想，在维护每一条数据索引号顺序不变的情况下，根据需求动态读取并处理某一列的数据。比如说，前面提到轨迹数据实际上是单独一列井号分割的字符串，我就按照当前顺序（维护索引号不变）把它提取出来，例如我可以把它变成一个不等长的列表，然后把它存储为二进制文件，这样下次就不必再弄一遍了。遇到要查询的数据，还可以建个索引方便快速查找，我感觉我这一块做的就有点像一个原始的数据库，所以论文里面直接就以数据库相称了。最困难的就是轨迹重排序的算法设计了，这个上面浪费了很多时间，一开始用的欧氏距离量两个点间的距离，速度很慢，而且对于浮点数有时还会遇到精度损失的问题。

3. 我看你论文中的图十分丰富，论文中的统计图表是如何制作的？是使用了什么专业软件吗？
   - 我主要使用Python语言编程绘制的，没有使用别的软件。主要用的一个叫做Matplotlib库，是一个科研绘图比较常用的库。一些地图的可视化用到了前端的技术，主要是基于百度地图提供的接口，比方说轨迹重排序的结果对比图就是用它做的。专题图的话还是用的传统的GIS软件。

4. 为什么要进行轨迹重排序？
   - 主要是原始轨迹并不是严格按照时间顺序，从起点到终点依次排列的，中间有些点是乱的。算法最核心的思路就是从起点开始找距离最近的点作为下一个点，这样一点点的直至重建完整个轨迹。

5. 道格拉斯-扑克算法的关键是什么？为何要使用它来处理轨迹数据？
   - 关键就是基于阈值作简化，也就是当前点到首尾点连线的垂距来决定哪些点要保留，哪些点可以舍去。最主要的就是想减少数据量，方便后面分析，测试了一部分轨迹之后发现还可以有效去除轨迹里面锯齿状的噪声，我又多试了几个阈值，找到最合适的那个保存了下来。这一块提高数据质量对后面的分析帮助还是特别大的。

## 开题答辩记录

1. 本研究有什么实际意义？
   本研究主要基于真实的共享单车骑行轨迹，探究通勤规律，为城市慢行交通系统建设提供科学参考。例如，本研究将分析骑行目的地组成及分布、骑行热点路段、借还车潮汐区域分布情况等，这些内容可用于共享单车调度优化等方面，进一步提升服务质量。
2. 研究数据是什么格式的？大体的处理思路？
   研究数据是CSV格式的表格文件，主要包含起止点坐标及对应的时间戳，其中轨迹数据是一个以井号分割的字符串。我打算首先对数据进行清洗，剔除有问题的记录，例如字段缺损、超出研究区域等。然后在保持数据顺序不变的情况下，将需要用到的列拆分成单独的文件，例如某一个研究需要用到轨迹数据，则可以将轨迹数据在不改变顺序的情况下，单独提取并存储为一个文件。
3. 研究大体思路是什么？
   主要从时间和空间两个方向去研究通勤模式。时间上，主要统计共享单车骑行轨迹的时间-距离分布模式、单车日周转率、用户骑行间隔总体分布情况及订单量日变化情况。空间上，我主要探究骑行终点分布及组成情况、骑行热点路段、各级别路段对骑行支撑情况、借还车潮汐分布情况等。这两个方向可以有效揭示共享单车骑行总体状况，以及骑行者、道路及基础设施之间的互动状况。
4. 简单介绍一下主要的研究方法？
   - 对于订单数据可以采用统计分析方法来探究数据的分布模式。对于轨迹数据，计划采用密度分析方法将其转化为栅格数据并进行进一步分析。例如，联合骑行轨迹线密度栅格和道路线密度栅格（同范围、同分辨率）可分析道路对骑行的支撑情况。对于骑行O-D模式可以采用均匀时空格网统计得到借还车栅格，并进一步结合潮汐指数及核密度分析得到总体的潮汐分布情况。
5. 难点是什么？有解决的思路了吗？
   轨迹数据的预处理是一个难点。原始轨迹数据存在乱序点，需要重建轨迹，同时，轨迹数据中普遍存在锯齿状噪声，需要想办法去除。轨迹重建算法已有思路，主要是从起点开始寻找最邻近的点，但是算法存在性能问题。锯齿状噪声可以视作一种无用的细节，选择合适的轨迹抽稀算法即可有效去除。另一个难点是轨迹仅包含位置信息，缺乏属性数据，难以进行分类等进一步分析。计划根据上海市兴趣的数据集，将轨迹终点匹配到最近的兴趣点上，算法已有思路但是存在性能问题。